{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsZvic2YxnTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zjh/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf #Since my tensorflow is 2.2.0 and bert is based on tensorflow 1.x\n",
    "from sklearn.model_selection import train_test_split\n",
    "#tf.disable_v2_behavior()\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pickle\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZM71PjIOF_I"
   },
   "outputs": [],
   "source": [
    "def pretty_print(result):\n",
    "    df = pd.DataFrame([result]).T\n",
    "    df.columns = [\"values\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZCYOL8HbIZu2"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module(bert_model_hub):\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(bert_model_hub)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
    "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    return features\n",
    "\n",
    "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      bert_model_hub,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n",
    "\n",
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        #f1_score = tf.contrib.metrics.f1_score(\n",
    "        #    label_ids,\n",
    "        #    predicted_labels)\n",
    "        auc = tf.metrics.auc(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predicted_labels) \n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            #\"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn\n",
    "\n",
    "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE, num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
    "\n",
    "    # Specify outpit directory and number of checkpoint steps to save\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        model_dir=OUTPUT_DIR,\n",
    "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "    model_fn = model_fn_builder(\n",
    "      bert_model_hub = bert_model_hub,\n",
    "      num_labels=len(label_list),\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      params={\"batch_size\": BATCH_SIZE})\n",
    "    return estimator, model_fn, run_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuMOGwFui4it"
   },
   "outputs": [],
   "source": [
    "def run_on_dfs(train, test, DATA_COLUMN, LABEL_COLUMN, \n",
    "               MAX_SEQ_LENGTH = 128,\n",
    "              BATCH_SIZE = 32,\n",
    "              LEARNING_RATE = 2e-5,\n",
    "              NUM_TRAIN_EPOCHS = 3.0,\n",
    "              WARMUP_PROPORTION = 0.1,\n",
    "              SAVE_SUMMARY_STEPS = 100,\n",
    "               SAVE_CHECKPOINTS_STEPS = 10000,\n",
    "              bert_model_hub = \"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\"):\n",
    "\n",
    "    label_list = train[LABEL_COLUMN].unique().tolist()\n",
    "    \n",
    "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
    "\n",
    "    train_features = make_features(train, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
    "    test_features = make_features(test, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "    estimator, model_fn, run_config = estimator_builder(\n",
    "                                  bert_model_hub, \n",
    "                                  OUTPUT_DIR, \n",
    "                                  SAVE_SUMMARY_STEPS, \n",
    "                                  SAVE_CHECKPOINTS_STEPS, \n",
    "                                  label_list, \n",
    "                                  LEARNING_RATE, \n",
    "                                  num_train_steps, \n",
    "                                  num_warmup_steps, \n",
    "                                  BATCH_SIZE)\n",
    "\n",
    "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "\n",
    "    test_input_fn = run_classifier.input_fn_builder(\n",
    "        features=test_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
    "    return result_dict, estimator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpUHTA8LIZu_"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmP8MBvjIZvB"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFBwDlmnIZvD"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('IMDB Dataset.csv')\n",
    "train,test=train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tju0c4dqIZvK"
   },
   "outputs": [],
   "source": [
    "train = train.sample(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9BAxyKhKirc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>length of text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8412</td>\n",
       "      <td>1st watched 2/18/2007 - 4 out of 10(Dir-Leon L...</td>\n",
       "      <td>2002</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13494</td>\n",
       "      <td>I am a regular reader of Kathy Reichs' Tempera...</td>\n",
       "      <td>1515</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7086</td>\n",
       "      <td>'I don't understand. None of this makes any se...</td>\n",
       "      <td>2192</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15524</td>\n",
       "      <td>I didn't have much high hopes for this one. Be...</td>\n",
       "      <td>1375</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47648</td>\n",
       "      <td>A desperate attempt to make a \"film-noir\" sci-...</td>\n",
       "      <td>341</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  length of text  \\\n",
       "8412   1st watched 2/18/2007 - 4 out of 10(Dir-Leon L...            2002   \n",
       "13494  I am a regular reader of Kathy Reichs' Tempera...            1515   \n",
       "7086   'I don't understand. None of this makes any se...            2192   \n",
       "15524  I didn't have much high hopes for this one. Be...            1375   \n",
       "47648  A desperate attempt to make a \"film-noir\" sci-...             341   \n",
       "\n",
       "      sentiment  \n",
       "8412   negative  \n",
       "13494  negative  \n",
       "7086   negative  \n",
       "15524  negative  \n",
       "47648  negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hM8M7k0gKk5H"
   },
   "outputs": [],
   "source": [
    "myparam = {\n",
    "        \"DATA_COLUMN\": \"review\",\n",
    "        \"BATCH_SIZE\":8,\n",
    "        \"LABEL_COLUMN\": \"sentiment\",\n",
    "        \"LEARNING_RATE\": 2e-5,\n",
    "        \"NUM_TRAIN_EPOCHS\":5,\n",
    "        \"bert_model_hub\":\"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.iloc[:3000]\n",
    "test=test.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dg2apeXpMqG-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 1st watched 2 / 18 / 2007 - 4 out of 10 ( Dir - Leon Leonard ) : Fair adventure movie based on a novel by the author of Mo ##by Dick fame , Herman Melville . This movie is about the captain of a ship who had stolen the eyes ( that were extremely rare black pe ##ar ##ls ) from a native tribe ' s God sculpture and hidden them some ##where that only he knew about before leaving the Island of Ti ##vi . He got very sick and was on a secret voyage to go back to the island to ret ##rie ##ve the pe ##ar ##ls for himself while others ( like his daughter ) thought that he was going [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] 1st watched 2 / 18 / 2007 - 4 out of 10 ( Dir - Leon Leonard ) : Fair adventure movie based on a novel by the author of Mo ##by Dick fame , Herman Melville . This movie is about the captain of a ship who had stolen the eyes ( that were extremely rare black pe ##ar ##ls ) from a native tribe ' s God sculpture and hidden them some ##where that only he knew about before leaving the Island of Ti ##vi . He got very sick and was on a secret voyage to go back to the island to ret ##rie ##ve the pe ##ar ##ls for himself while others ( like his daughter ) thought that he was going [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 13510 92147 123 120 10218 120 10202 118 125 10950 10108 10150 113 67961 118 19409 20318 114 131 25697 67865 18379 11610 10135 169 14671 10155 10105 17034 10108 34987 11530 19988 51930 117 22303 72309 119 10747 18379 10124 10978 10105 28157 10108 169 17309 10479 10374 78173 10105 38144 113 10189 10309 38136 23902 15045 11161 10354 11747 114 10188 169 20030 40964 112 187 14015 38359 10111 57786 11345 11152 30935 10189 10893 10261 46000 10978 11360 21005 10105 11848 10108 29033 11310 119 10357 19556 12558 101003 10111 10134 10135 169 23658 28793 10114 11783 12014 10114 10105 17354 10114 62893 12904 10612 10105 11161 10354 11747 10142 14764 11371 14633 113 11850 10226 15243 114 18957 10189 10261 10134 19090 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 13510 92147 123 120 10218 120 10202 118 125 10950 10108 10150 113 67961 118 19409 20318 114 131 25697 67865 18379 11610 10135 169 14671 10155 10105 17034 10108 34987 11530 19988 51930 117 22303 72309 119 10747 18379 10124 10978 10105 28157 10108 169 17309 10479 10374 78173 10105 38144 113 10189 10309 38136 23902 15045 11161 10354 11747 114 10188 169 20030 40964 112 187 14015 38359 10111 57786 11345 11152 30935 10189 10893 10261 46000 10978 11360 21005 10105 11848 10108 29033 11310 119 10357 19556 12558 101003 10111 10134 10135 169 23658 28793 10114 11783 12014 10114 10105 17354 10114 62893 12904 10612 10105 11161 10354 11747 10142 14764 11371 14633 113 11850 10226 15243 114 18957 10189 10261 10134 19090 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] I am a regular reader of Kathy Reich ##s ' Tem ##pera ##nce Brennan novels . As such I am extremely surprise ##d she even consul ##ted on this show . < br / > < br / > It is H ##OR ##RI ##BL ##E by comparison to the books . The Tem ##pera ##nce Brennan character is , in the books , a down to earth recover ##ing alcohol ##ic and divorced mo ##m of a college aged daughter . In ' Bones ' , she is an ar ##roga ##nt ( r ##hy ##mes with rich ) , who , in typical P C fashion , is not a mother . The emphasis on her assist ##ing staff , complete with lu ##rid [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] I am a regular reader of Kathy Reich ##s ' Tem ##pera ##nce Brennan novels . As such I am extremely surprise ##d she even consul ##ted on this show . < br / > < br / > It is H ##OR ##RI ##BL ##E by comparison to the books . The Tem ##pera ##nce Brennan character is , in the books , a down to earth recover ##ing alcohol ##ic and divorced mo ##m of a college aged daughter . In ' Bones ' , she is an ar ##roga ##nt ( r ##hy ##mes with rich ) , who , in typical P C fashion , is not a mother . The emphasis on her assist ##ing staff , complete with lu ##rid [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 146 10392 169 15670 84288 10108 67888 19396 10107 112 53696 37097 12150 74578 41116 119 10882 11049 146 10392 38136 48886 10162 10833 13246 53704 11912 10135 10531 11897 119 133 33989 120 135 133 33989 120 135 10377 10124 145 42622 46876 94701 11259 10155 56542 10114 10105 15174 119 10117 53696 37097 12150 74578 15092 10124 117 10106 10105 15174 117 169 12935 10114 39189 94962 10230 36067 11130 10111 81440 46912 10147 10108 169 16083 30262 15243 119 10167 112 59656 112 117 10833 10124 10151 10456 59648 10368 113 186 19275 13546 10169 33250 114 117 10479 117 10106 36772 153 140 35055 117 10124 10472 169 15293 119 10117 60848 10135 10485 40960 10230 18927 117 17876 10169 14657 33597 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 146 10392 169 15670 84288 10108 67888 19396 10107 112 53696 37097 12150 74578 41116 119 10882 11049 146 10392 38136 48886 10162 10833 13246 53704 11912 10135 10531 11897 119 133 33989 120 135 133 33989 120 135 10377 10124 145 42622 46876 94701 11259 10155 56542 10114 10105 15174 119 10117 53696 37097 12150 74578 15092 10124 117 10106 10105 15174 117 169 12935 10114 39189 94962 10230 36067 11130 10111 81440 46912 10147 10108 169 16083 30262 15243 119 10167 112 59656 112 117 10833 10124 10151 10456 59648 10368 113 186 19275 13546 10169 33250 114 117 10479 117 10106 36772 153 140 35055 117 10124 10472 169 15293 119 10117 60848 10135 10485 40960 10230 18927 117 17876 10169 14657 33597 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ' I don ' t understand . None of this makes any sense ! ' , ex ##cla ##im ##s one ex ##as ##perate ##d character towards the end of Death Smile ##s at Murder . Having just sat through this th ##oro ##ugh ##ly con ##fus ##ing mes ##s of a movie , I know exactly how he feels . The story , by the film ' s director Ari ##stide Massa ##ces ##si ( good old Joe D ' amat ##o using his real name for a change ) , is a c ##lum ##sy mix of the super ##natural , murder / mystery , and pret ##enti ##ous art ##y ru ##bbi ##sh , the like ##s of which will probably appeal to [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ' I don ' t understand . None of this makes any sense ! ' , ex ##cla ##im ##s one ex ##as ##perate ##d character towards the end of Death Smile ##s at Murder . Having just sat through this th ##oro ##ugh ##ly con ##fus ##ing mes ##s of a movie , I know exactly how he feels . The story , by the film ' s director Ari ##stide Massa ##ces ##si ( good old Joe D ' amat ##o using his real name for a change ) , is a c ##lum ##sy mix of the super ##natural , murder / mystery , and pret ##enti ##ous art ##y ru ##bbi ##sh , the like ##s of which will probably appeal to [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 112 146 16938 112 188 49151 119 86481 10108 10531 20562 11178 15495 106 112 117 11419 60582 11759 10107 10464 11419 10403 71470 10162 15092 18095 10105 11572 10108 15467 56928 10107 10160 30109 119 50195 12820 20694 11222 10531 77586 30700 25905 10454 10173 55729 10230 17954 10107 10108 169 18379 117 146 21852 62136 14796 10261 84992 119 10117 13617 117 10155 10105 10458 112 187 12461 19365 87642 41203 14585 10449 113 15198 12898 13062 141 112 79459 10133 13382 10226 13486 11324 10142 169 15453 114 117 10124 169 171 20571 16105 28236 10108 10105 25212 56124 117 29448 120 84058 117 10111 49775 21688 13499 11938 10157 13483 37801 13264 117 10105 11850 10107 10108 10319 11337 23282 44861 10114 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 112 146 16938 112 188 49151 119 86481 10108 10531 20562 11178 15495 106 112 117 11419 60582 11759 10107 10464 11419 10403 71470 10162 15092 18095 10105 11572 10108 15467 56928 10107 10160 30109 119 50195 12820 20694 11222 10531 77586 30700 25905 10454 10173 55729 10230 17954 10107 10108 169 18379 117 146 21852 62136 14796 10261 84992 119 10117 13617 117 10155 10105 10458 112 187 12461 19365 87642 41203 14585 10449 113 15198 12898 13062 141 112 79459 10133 13382 10226 13486 11324 10142 169 15453 114 117 10124 169 171 20571 16105 28236 10108 10105 25212 56124 117 29448 120 84058 117 10111 49775 21688 13499 11938 10157 13483 37801 13264 117 10105 11850 10107 10108 10319 11337 23282 44861 10114 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] I didn ' t have much high hopes for this one . Before seeing it , the story ye ##lle ##d \" stereo ##type \" at me . < br / > < br / > I mean . . . come on ! It ' s so st ##upi ##d the plot line about the inn ##ocent andro ##id that real ##izes that the people who created him are im ##mora ##l , then decides to change everything . < br / > < br / > I had to see it three times . The first two times I fell asl ##eep because I was so in ##cre ##di ##bly bore ##d by it . It ' s very rare that movies bore me [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] I didn ' t have much high hopes for this one . Before seeing it , the story ye ##lle ##d \" stereo ##type \" at me . < br / > < br / > I mean . . . come on ! It ' s so st ##upi ##d the plot line about the inn ##ocent andro ##id that real ##izes that the people who created him are im ##mora ##l , then decides to change everything . < br / > < br / > I had to see it three times . The first two times I fell asl ##eep because I was so in ##cre ##di ##bly bore ##d by it . It ' s very rare that movies bore me [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 146 34420 112 188 10529 13172 11846 82467 10142 10531 10464 119 19318 57039 10271 117 10105 13617 11023 11270 10162 107 109969 54960 107 10160 10911 119 133 33989 120 135 133 33989 120 135 146 36110 119 119 119 10678 10135 106 10377 112 187 10380 28780 90695 10162 10105 32473 12117 10978 10105 15203 103528 54085 11249 10189 13486 59080 10189 10105 11426 10479 13745 10957 10301 10211 79374 10161 117 11059 56253 10114 15453 42536 119 133 33989 120 135 133 33989 120 135 146 10374 10114 12888 10271 11003 13465 119 10117 10422 10551 13465 146 25194 24491 91633 12373 146 10134 10380 10106 27794 10703 31748 73823 10162 10155 10271 119 10377 112 187 12558 23902 10189 39129 73823 10911 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 146 34420 112 188 10529 13172 11846 82467 10142 10531 10464 119 19318 57039 10271 117 10105 13617 11023 11270 10162 107 109969 54960 107 10160 10911 119 133 33989 120 135 133 33989 120 135 146 36110 119 119 119 10678 10135 106 10377 112 187 10380 28780 90695 10162 10105 32473 12117 10978 10105 15203 103528 54085 11249 10189 13486 59080 10189 10105 11426 10479 13745 10957 10301 10211 79374 10161 117 11059 56253 10114 15453 42536 119 133 33989 120 135 133 33989 120 135 146 10374 10114 12888 10271 11003 13465 119 10117 10422 10551 13465 146 25194 24491 91633 12373 146 10134 10380 10106 27794 10703 31748 73823 10162 10155 10271 119 10377 112 187 12558 23902 10189 39129 73823 10911 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] A des ##perate attempt to make a \" film - noir \" sci - fi thriller , but the movie falls short . It has no bel ##ie ##vab ##le plot , some of the key actors were a jo ##ke ( NO ##T Lars Bom , he is cool ! ) . I did like the \" access rest ##ric ##tion by band ##wit ##h maxim ##izing \" though . I finished it on principle , but went home with the feeling of having lost two hours of my life . . . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] A des ##perate attempt to make a \" film - noir \" sci - fi thriller , but the movie falls short . It has no bel ##ie ##vab ##le plot , some of the key actors were a jo ##ke ( NO ##T Lars Bom , he is cool ! ) . I did like the \" access rest ##ric ##tion by band ##wit ##h maxim ##izing \" though . I finished it on principle , but went home with the feeling of having lost two hours of my life . . . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 138 10139 71470 21395 10114 13086 169 107 10458 118 25897 107 58803 118 14045 45768 117 10473 10105 18379 35017 13716 119 10377 10393 10192 65817 10400 93870 10284 32473 117 11152 10108 10105 18444 36189 10309 169 12541 10550 113 49307 11090 21574 67618 117 10261 10124 67420 106 114 119 146 12172 11850 10105 107 18314 17333 18570 10822 10155 11570 56082 10237 70916 39949 107 15102 119 146 15972 10271 10135 48300 117 10473 13446 11816 10169 10105 61362 10108 13677 14172 10551 19573 10108 15127 12103 119 119 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 138 10139 71470 21395 10114 13086 169 107 10458 118 25897 107 58803 118 14045 45768 117 10473 10105 18379 35017 13716 119 10377 10393 10192 65817 10400 93870 10284 32473 117 11152 10108 10105 18444 36189 10309 169 12541 10550 113 49307 11090 21574 67618 117 10261 10124 67420 106 114 119 146 12172 11850 10105 107 18314 17333 18570 10822 10155 11570 56082 10237 70916 39949 107 15102 119 146 15972 10271 10135 48300 117 10473 13446 11816 10169 10105 61362 10108 13677 14172 10551 19573 10108 15127 12103 119 119 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Return of the Boo ##gy ##man is a dre ##ad ##ful movie which doesn ' t play like a movie , it plays like an episode of a TV sitcom when they flash ##back to older episodes . Return of the Boo ##gy ##man is just a clip show . < br / > < br / > Mu ##tch of the film is constant and anno ##ying flash ##backs from the first movie . Over and over again the same footage . How bor ##ing this is . < br / > < br / > The movie really is about a ps ##ych ##ic woman who has vision ##s of the first movie . < br / > < br / > I have [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Return of the Boo ##gy ##man is a dre ##ad ##ful movie which doesn ' t play like a movie , it plays like an episode of a TV sitcom when they flash ##back to older episodes . Return of the Boo ##gy ##man is just a clip show . < br / > < br / > Mu ##tch of the film is constant and anno ##ying flash ##backs from the first movie . Over and over again the same footage . How bor ##ing this is . < br / > < br / > The movie really is about a ps ##ych ##ic woman who has vision ##s of the first movie . < br / > < br / > I have [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 28736 10108 10105 102498 17113 10589 10124 169 35028 11488 14446 18379 10319 47798 112 188 12253 11850 169 18379 117 10271 17724 11850 10151 14320 10108 169 10813 70498 10841 10689 59946 18666 10114 18757 23604 119 28736 10108 10105 102498 17113 10589 10124 12820 169 48545 11897 119 133 33989 120 135 133 33989 120 135 49056 38732 10108 10105 10458 10124 29152 10111 11671 40018 59946 68694 10188 10105 10422 18379 119 15704 10111 10491 13123 10105 11561 67953 119 14962 27728 10230 10531 10124 119 133 33989 120 135 133 33989 120 135 10117 18379 30181 10124 10978 169 97764 14950 11130 18299 10479 10393 30237 10107 10108 10105 10422 18379 119 133 33989 120 135 133 33989 120 135 146 10529 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 28736 10108 10105 102498 17113 10589 10124 169 35028 11488 14446 18379 10319 47798 112 188 12253 11850 169 18379 117 10271 17724 11850 10151 14320 10108 169 10813 70498 10841 10689 59946 18666 10114 18757 23604 119 28736 10108 10105 102498 17113 10589 10124 12820 169 48545 11897 119 133 33989 120 135 133 33989 120 135 49056 38732 10108 10105 10458 10124 29152 10111 11671 40018 59946 68694 10188 10105 10422 18379 119 15704 10111 10491 13123 10105 11561 67953 119 14962 27728 10230 10531 10124 119 133 33989 120 135 133 33989 120 135 10117 18379 30181 10124 10978 169 97764 14950 11130 18299 10479 10393 30237 10107 10108 10105 10422 18379 119 133 33989 120 135 133 33989 120 135 146 10529 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] A ##w ##ful , con ##fus ##ing bit of c ##rap from South of the Border . I ' ve now watched it twice and I ST ##IL ##L don ' t really know what was going on . It had something to do with a st ##upi ##d looking Az ##tec mu ##mmy , a ' human robot ' that ' s the dum ##bes ##t looking robot I ' ve ever seen bar none , and a woman who is the rein ##car ##nation of some ancient Az ##tec chi ##ck . Most of the story is told in a pain ##fully slow and dro ##ning manner by an in ##cre ##di ##bly du ##ll scientist . This gu ##y is a mar ##vel [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] A ##w ##ful , con ##fus ##ing bit of c ##rap from South of the Border . I ' ve now watched it twice and I ST ##IL ##L don ' t really know what was going on . It had something to do with a st ##upi ##d looking Az ##tec mu ##mmy , a ' human robot ' that ' s the dum ##bes ##t looking robot I ' ve ever seen bar none , and a woman who is the rein ##car ##nation of some ancient Az ##tec chi ##ck . Most of the story is told in a pain ##fully slow and dro ##ning manner by an in ##cre ##di ##bly du ##ll scientist . This gu ##y is a mar ##vel [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 138 10874 14446 117 10173 55729 10230 17684 10108 171 53750 10188 11056 10108 10105 57089 119 146 112 10323 11858 92147 10271 26261 10111 146 53317 38850 11369 16938 112 188 30181 21852 12976 10134 19090 10135 119 10377 10374 26133 10114 10149 10169 169 28780 90695 10162 34279 11122 64764 12361 73549 117 169 112 14179 36945 112 10189 112 187 10105 54892 16216 10123 34279 36945 146 112 10323 17038 15652 18121 46638 117 10111 169 18299 10479 10124 10105 74720 15983 22711 10108 11152 21226 11122 64764 14325 11263 119 14361 10108 10105 13617 10124 21937 10106 169 38576 42920 41573 10111 33741 11269 39750 10155 10151 10106 27794 10703 31748 10168 11231 59248 119 10747 75980 10157 10124 169 12318 13128 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 138 10874 14446 117 10173 55729 10230 17684 10108 171 53750 10188 11056 10108 10105 57089 119 146 112 10323 11858 92147 10271 26261 10111 146 53317 38850 11369 16938 112 188 30181 21852 12976 10134 19090 10135 119 10377 10374 26133 10114 10149 10169 169 28780 90695 10162 34279 11122 64764 12361 73549 117 169 112 14179 36945 112 10189 112 187 10105 54892 16216 10123 34279 36945 146 112 10323 17038 15652 18121 46638 117 10111 169 18299 10479 10124 10105 74720 15983 22711 10108 11152 21226 11122 64764 14325 11263 119 14361 10108 10105 13617 10124 21937 10106 169 38576 42920 41573 10111 33741 11269 39750 10155 10151 10106 27794 10703 31748 10168 11231 59248 119 10747 75980 10157 10124 169 12318 13128 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] I ' m sure deep in the re ##cesse ##s of Jack Blacks mind the character of Nach ##o Libre is absolute ##ly hil ##ario ##us but no it isn ' t . You can tell ol Jack ##s having a w ##hale of a time ham ##min it up playing a sm ##arm ##y , sl ##im ##y Mexican fri ##ar with dreams of becoming a wrestler but this movie is a total mis ##fire in just about every single department . < br / > < br / > I just sat there through most of the movie thinking \" Is this supposed to be fun ##ny \" and \" This is the gu ##y from Ten ##aci ##ous D right ? \" . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] I ' m sure deep in the re ##cesse ##s of Jack Blacks mind the character of Nach ##o Libre is absolute ##ly hil ##ario ##us but no it isn ' t . You can tell ol Jack ##s having a w ##hale of a time ham ##min it up playing a sm ##arm ##y , sl ##im ##y Mexican fri ##ar with dreams of becoming a wrestler but this movie is a total mis ##fire in just about every single department . < br / > < br / > I just sat there through most of the movie thinking \" Is this supposed to be fun ##ny \" and \" This is the gu ##y from Ten ##aci ##ous D right ? \" . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 146 112 181 62452 26591 10106 10105 11639 106752 10107 10108 12342 107375 21133 10105 15092 10108 11505 10133 46116 10124 48573 10454 48989 16780 10251 10473 10192 10271 98370 112 188 119 11065 10944 41549 30668 12342 10107 13677 169 191 39149 10108 169 10635 15128 14956 10271 10741 14879 169 39709 76171 10157 117 38523 11759 10157 15323 35350 10354 10169 101990 10108 19881 169 62098 10473 10531 18379 10124 169 11339 12606 38990 10106 12820 10978 14234 11376 21079 119 133 33989 120 135 133 33989 120 135 146 12820 20694 11155 11222 10992 10108 10105 18379 56294 107 12034 10531 59516 10114 10347 41807 10756 107 10111 107 10747 10124 10105 75980 10157 10188 16411 28841 13499 141 13448 136 107 119 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 146 112 181 62452 26591 10106 10105 11639 106752 10107 10108 12342 107375 21133 10105 15092 10108 11505 10133 46116 10124 48573 10454 48989 16780 10251 10473 10192 10271 98370 112 188 119 11065 10944 41549 30668 12342 10107 13677 169 191 39149 10108 169 10635 15128 14956 10271 10741 14879 169 39709 76171 10157 117 38523 11759 10157 15323 35350 10354 10169 101990 10108 19881 169 62098 10473 10531 18379 10124 169 11339 12606 38990 10106 12820 10978 14234 11376 21079 119 133 33989 120 135 133 33989 120 135 146 12820 20694 11155 11222 10992 10108 10105 18379 56294 107 12034 10531 59516 10114 10347 41807 10756 107 10111 107 10747 10124 10105 75980 10157 10188 16411 28841 13499 141 13448 136 107 119 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] This movie is traditional bol ##ly ##wood fare as far as the star power , sentiment ##ali ##ty and love triangle of em ##otions . What really both ##ered me about this movie was the makers ' ab ##sur ##d notion of sur ##roga ##te mother . A who ##re who con ##cei ##ves a child with someone after have sex with the man ( of the family des ##irin ##g a child ) is not a sur ##roga ##te mother . Nei ##ther is she a good candidate for a sur ##roga ##te mother . I have seen Indian movies and television shows that made 10 to 15 years ago that dealt with this issue more intelligent ##ly . The whole concept of the movie [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] This movie is traditional bol ##ly ##wood fare as far as the star power , sentiment ##ali ##ty and love triangle of em ##otions . What really both ##ered me about this movie was the makers ' ab ##sur ##d notion of sur ##roga ##te mother . A who ##re who con ##cei ##ves a child with someone after have sex with the man ( of the family des ##irin ##g a child ) is not a sur ##roga ##te mother . Nei ##ther is she a good candidate for a sur ##roga ##te mother . I have seen Indian movies and television shows that made 10 to 15 years ago that dealt with this issue more intelligent ##ly . The whole concept of the movie [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10747 18379 10124 17531 14038 10454 14759 23252 10146 13301 10146 10105 16624 13183 117 70762 13133 11195 10111 16138 65788 10108 10266 94409 119 12489 30181 11408 45452 10911 10978 10531 18379 10134 10105 104213 112 11357 66679 10162 48213 10108 10326 59648 10216 15293 119 138 10479 10246 10479 10173 91199 13136 169 18048 10169 30455 10662 10529 18549 10169 10105 10817 113 10108 10105 11365 10139 89080 10240 169 18048 114 10124 10472 169 10326 59648 10216 15293 119 25822 22623 10124 10833 169 15198 22102 10142 169 10326 59648 10216 15293 119 146 10529 15652 12544 39129 10111 14162 15573 10189 11019 10150 10114 10208 10855 36390 10189 102810 10169 10531 15557 10798 75856 10454 119 10117 21047 19228 10108 10105 18379 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10747 18379 10124 17531 14038 10454 14759 23252 10146 13301 10146 10105 16624 13183 117 70762 13133 11195 10111 16138 65788 10108 10266 94409 119 12489 30181 11408 45452 10911 10978 10531 18379 10134 10105 104213 112 11357 66679 10162 48213 10108 10326 59648 10216 15293 119 138 10479 10246 10479 10173 91199 13136 169 18048 10169 30455 10662 10529 18549 10169 10105 10817 113 10108 10105 11365 10139 89080 10240 169 18048 114 10124 10472 169 10326 59648 10216 15293 119 25822 22623 10124 10833 169 15198 22102 10142 169 10326 59648 10216 15293 119 146 10529 15652 12544 39129 10111 14162 15573 10189 11019 10150 10114 10208 10855 36390 10189 102810 10169 10531 15557 10798 75856 10454 119 10117 21047 19228 10108 10105 18379 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Cameron Mitchell plays an actor who is dating a young actress who used to date the head of a movie studio ( she ' s too young for both of them ! ) . At a party , when he ' s lighting his ci ##gare ##tte , the studio boss throw ##s a high alcohol content drink in his face , and he catch ##es fire . In the hospital , his face is entirely banda ##ged and he still lights up a ci ##gare ##tte ! He becomes the resident sculptor of the Movie ##land W ##ax Museum and Palace , where he also lights up ci ##gare ##ttes ! < br / > < br / > Mitchell recover ##s , more or [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Cameron Mitchell plays an actor who is dating a young actress who used to date the head of a movie studio ( she ' s too young for both of them ! ) . At a party , when he ' s lighting his ci ##gare ##tte , the studio boss throw ##s a high alcohol content drink in his face , and he catch ##es fire . In the hospital , his face is entirely banda ##ged and he still lights up a ci ##gare ##tte ! He becomes the resident sculptor of the Movie ##land W ##ax Museum and Palace , where he also lights up ci ##gare ##ttes ! < br / > < br / > Mitchell recover ##s , more or [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 21678 19906 17724 10151 14066 10479 10124 33573 169 14739 24268 10479 11031 10114 13664 10105 13578 10108 169 18379 13093 113 10833 112 187 16683 14739 10142 11408 10108 11345 106 114 119 11699 169 14039 117 10841 10261 112 187 77805 10226 11322 30671 12131 117 10105 13093 48246 73696 10107 169 11846 36067 19509 69423 10106 10226 13295 117 10111 10261 61093 10171 13559 119 10167 10105 18141 117 10226 13295 10124 34053 12274 18832 10111 10261 12647 71123 10741 169 11322 30671 12131 106 10357 23785 10105 44192 78793 10108 10105 14785 11080 160 31691 11325 10111 22015 117 10940 10261 10379 71123 10741 11322 30671 23863 106 133 33989 120 135 133 33989 120 135 19906 94962 10107 117 10798 10345 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 21678 19906 17724 10151 14066 10479 10124 33573 169 14739 24268 10479 11031 10114 13664 10105 13578 10108 169 18379 13093 113 10833 112 187 16683 14739 10142 11408 10108 11345 106 114 119 11699 169 14039 117 10841 10261 112 187 77805 10226 11322 30671 12131 117 10105 13093 48246 73696 10107 169 11846 36067 19509 69423 10106 10226 13295 117 10111 10261 61093 10171 13559 119 10167 10105 18141 117 10226 13295 10124 34053 12274 18832 10111 10261 12647 71123 10741 169 11322 30671 12131 106 10357 23785 10105 44192 78793 10108 10105 14785 11080 160 31691 11325 10111 22015 117 10940 10261 10379 71123 10741 11322 30671 23863 106 133 33989 120 135 133 33989 120 135 19906 94962 10107 117 10798 10345 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: negative (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x147fd6490>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x147fd6490>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/Users/zjh/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output/model.ckpt-112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output/model.ckpt-112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 112 into output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 112 into output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019162808, step = 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019162808, step = 113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 187 into output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 187 into output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.002018882.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.002018882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/Users/zjh/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-03T16:52:31Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-03T16:52:31Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output/model.ckpt-187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output/model.ckpt-187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-03-16:52:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-03-16:52:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 187: auc = 0.8097239, eval_accuracy = 0.81, false_negatives = 10.0, false_positives = 9.0, global_step = 187, loss = 0.9250784, precision = 0.8125, recall = 0.79591835, true_negatives = 42.0, true_positives = 39.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 187: auc = 0.8097239, eval_accuracy = 0.81, false_negatives = 10.0, false_positives = 9.0, global_step = 187, loss = 0.9250784, precision = 0.8125, recall = 0.79591835, true_negatives = 42.0, true_positives = 39.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187: output/model.ckpt-187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187: output/model.ckpt-187\n"
     ]
    }
   ],
   "source": [
    "result, estimator = run_on_dfs(train, test, **myparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLOvtveTMqwp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>auc</td>\n",
       "      <td>0.809724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>false_negatives</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>false_positives</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>loss</td>\n",
       "      <td>0.925078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall</td>\n",
       "      <td>0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_negatives</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_positives</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>global_step</td>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     values\n",
       "auc                0.809724\n",
       "eval_accuracy      0.810000\n",
       "false_negatives   10.000000\n",
       "false_positives    9.000000\n",
       "loss               0.925078\n",
       "precision          0.812500\n",
       "recall             0.795918\n",
       "true_negatives    42.000000\n",
       "true_positives    39.000000\n",
       "global_step      187.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0OPTDcGMsJw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "demo-chinese-text-binary-classification-with-bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
